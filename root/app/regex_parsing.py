"""
FanFicFare Output Parsing and URL Processing

This module provides regular expression-based parsing of FanFicFare command-line
output to detect success/failure conditions, extract metadata, and process URLs
for fanfiction downloads. It serves as the primary interface between the raw
FanFicFare output and the AutomatedFanfic application logic.

Key Features:
    - FanFicFare output parsing for status detection
    - URL normalization and site identification
    - Error condition detection with specific failure types
    - Force update condition detection for retry logic
    - Automatic site recognition via auto-generated parsers

Architecture:
    The module uses compiled regular expressions to efficiently parse FanFicFare
    output text. It categorizes output into success, retryable failures, and
    permanent failures to guide the application's retry logic.

URL Processing Flow:
    1. Input URL is tested against auto-generated site parsers
    2. Matching parser extracts the story ID or URL components
    3. URL is normalized using the site's prefix pattern
    4. FanficInfo object is created with site identification
    5. Falls back to "other" site for unrecognized URLs

Error Detection:
    The module detects several categories of errors from FanFicFare output:
    - Permanent failures (bad metadata, login issues, forbidden access)
    - Retryable conditions (chapter mismatches, timing issues)
    - Site-specific problems (CloudFlare protection, rate limiting)

Example:
    ```python
    from regex_parsing import generate_FanficInfo_from_url, check_failure_regexes
    from auto_url_parsers import generate_url_parsers_from_fanficfare

    # Generate URL parsers and parse URL to identify site
    url_parsers = generate_url_parsers_from_fanficfare()
    fanfic_info = generate_FanficInfo_from_url("https://archiveofourown.org/works/12345", url_parsers)

    # Check FanFicFare output for errors
    if check_failure_regexes(fanficfare_output):
        print("Download succeeded")
    else:
        print("Download failed")
    ```

Dependencies:
    - auto_url_parsers: Provides automatically generated URL pattern recognition
    - fanfic_info: Defines FanficInfo data structures
    - ff_logging: Provides logging capabilities for error reporting

Note:
    This module relies on auto_url_parsers for site recognition, which
    automatically generates URL patterns from FanFicFare's adapter definitions.
    This eliminates the need for manual regex maintenance as new sites are added.
"""

import os
import re
import fanfic_info
import ff_logging

# Note: url_parsers is now passed as a parameter to avoid loading
# FanFicFare adapters in every worker process

# Define regular expressions for different story formats and errors
# These patterns are used to parse FanFicFare output for various conditions

# Pattern to extract story title from filename (removes file extension and ID suffix)
story_name = re.compile(r"(.*)-[^-]*$")

# Patterns for detecting various error conditions in FanFicFare output
equal_chapters = re.compile(r".* already contains (\d+) chapters.")
chapter_difference = re.compile(r".* contains (\d+) chapters, more than source: (\d+).")
bad_chapters = re.compile(
    r".* doesn't contain any recognizable chapters, probably from a different source.  Not updating."
)
no_url = re.compile(r"No story URL found in epub to update.")
more_chapters = re.compile(
    r".*File\(.*\.epub\) Updated\(.*\) more recently than Story\(.*\) - Skipping"
)
failed_login = re.compile(
    r".*Login Failed on non-interactive process. Set username and password in personal.ini."
)
bad_request = re.compile(r".*400 Client Error: Bad Request for url:.*")
forbidden_client = re.compile(r".*403 Client Error: Forbidden for url:.*")
flaresolverr = re.compile(r".*Connection to flaresolverr proxy server failed.*")


def extract_filename(filename: str) -> str:
    """
    Extract the story title from a fanfiction filename.

    This function removes file extensions and ID suffixes to extract the
    clean story title from fanfiction filenames generated by FanFicFare.

    Args:
        filename: The full filename path or basename containing the story
                 title and ID suffix (e.g., "Story Title-123456.epub")

    Returns:
        str: The extracted story title with leading/trailing whitespace
             removed, or the original filename if no pattern match found.

    Example:
        ```python
        title = extract_filename("My Favorite Story-789123.epub")
        # Returns: "My Favorite Story"

        title = extract_filename("/path/to/Another Story-456.txt")
        # Returns: "Another Story"
        ```

    Note:
        This function expects filenames to follow FanFicFare's naming
        convention of "Title-ID.extension". If the pattern doesn't match,
        the original filename is returned after trimming whitespace.
    """
    # Extract just the filename portion, removing any directory path
    basenamed_filepath = os.path.basename(filename)

    # Try to match the expected "Title-ID" pattern
    match = story_name.search(basenamed_filepath)
    return match.group(1).strip() if match else basenamed_filepath.strip()


def check_regexes(output: str, regex: re.Pattern, message: str) -> bool:
    """
    Test output against a regex pattern and log a failure message if matched.

    This is a utility function used by the failure and forceable regex
    checkers to test FanFicFare output against specific error patterns.

    Args:
        output: The FanFicFare command output text to test
        regex: Compiled regular expression pattern to match against
        message: Error message to log if the pattern matches

    Returns:
        bool: True if the regex pattern matches the output text,
              False otherwise

    Side Effects:
        Logs a failure message via ff_logging if the pattern matches

    Example:
        ```python
        failed_login_pattern = re.compile(r"Login Failed")
        if check_regexes(output, failed_login_pattern, "Authentication failed"):
            # Handle login failure
            pass
        ```

    Note:
        This function is primarily used internally by check_failure_regexes
        and check_forceable_regexes to provide consistent logging behavior
        across all error detection patterns.
    """
    if regex.search(output):
        ff_logging.log_failure(message)
        return True
    return False


def check_failure_regexes(output: str) -> bool:
    """
    Test FanFicFare output for permanent failure conditions.

    This function checks the FanFicFare command output against a series of
    regular expressions that identify permanent failure conditions. These
    are errors that typically cannot be resolved by retrying the operation.

    Args:
        output: The complete text output from a FanFicFare command execution

    Returns:
        bool: True if NO failure patterns were detected (success case),
              False if any permanent failure pattern was found

    Failure Categories Detected:
        - Chapter mismatch errors (story already contains X chapters)
        - Metadata corruption (no recognizable chapters found)
        - Missing URL metadata (no story URL found in epub)
        - Authentication failures (login failed)
        - HTTP client errors (400 Bad Request, 403 Forbidden)
        - Infrastructure failures (Flaresolverr connection issues)

    Example:
        ```python
        fanficfare_output = run_fanficfare_command(url)

        if check_failure_regexes(fanficfare_output):
            print("Download completed successfully")
            send_success_notification()
        else:
            print("Download failed with permanent error")
            handle_permanent_failure()
        ```

    Note:
        This function returns True for success (no failures detected) to
        maintain backward compatibility with existing code that expects
        a success boolean. Each detected failure is logged via ff_logging.
    """
    # Define permanent failure patterns and their user-friendly messages
    failure_regexes = [
        (
            equal_chapters,
            "Issue with story, site is broken. Story likely hasn't updated on site yet.",
        ),
        (
            bad_chapters,
            "Something is messed up with the site or the epub. No chapters found.",
        ),
        (no_url, "No URL in epub to update from. Fix the metadata."),
        (failed_login, "Login failed. Check your username and password."),
        (bad_request, "Bad request. Check the URL."),
        (
            forbidden_client,
            "Forbidden client. Check the URL. If this is ff.net, check that you have Flaresolverr installed, or cry.",
        ),
        (
            flaresolverr,
            "Flaresolverr connection failed. Check your Flaresolverr installation.",
        ),
    ]

    # Return True if NO failures detected (success case)
    return not any(
        check_regexes(output, regex, message) for regex, message in failure_regexes
    )


def check_forceable_regexes(output: str) -> bool:
    """
    Test FanFicFare output for conditions that can be resolved with force update.

    This function identifies specific error conditions in FanFicFare output
    that indicate the download failed due to timing or metadata issues that
    can typically be resolved by forcing an update with the --force flag.

    Args:
        output: The complete text output from a FanFicFare command execution

    Returns:
        bool: True if any forceable condition was detected (retry with --force),
              False if no forceable conditions were found

    Forceable Conditions Detected:
        - Chapter count mismatch between source and destination
        - File timestamp newer than story timestamp (metadata bug)
        - Other timing-related inconsistencies that --force can resolve

    Example:
        ```python
        fanficfare_output = run_fanficfare_command(url)

        if not check_failure_regexes(fanficfare_output):
            if check_forceable_regexes(fanficfare_output):
                print("Retrying with force update...")
                retry_with_force_flag(url)
            else:
                print("Permanent failure - cannot retry")
        ```

    Integration with Retry Logic:
        This function is used by the application's retry logic to determine
        whether a failed download should be retried with the --force flag.
        It helps distinguish between retryable conditions and permanent failures.

    Note:
        Each detected forceable condition is logged via ff_logging with
        a descriptive message explaining why the force update is needed.
    """
    # Define conditions that can be resolved with --force flag
    forceable_regexes = [
        (
            chapter_difference,
            "Chapter difference between source and destination. Forcing update.",
        ),
        (
            more_chapters,
            "File has been updated more recently than the story, this is likely a metadata bug. Forcing update.",
        ),
    ]

    # Return True if ANY forceable condition is detected
    return any(
        check_regexes(output, regex, message) for regex, message in forceable_regexes
    )


def generate_FanficInfo_from_url(url: str, url_parsers: dict) -> fanfic_info.FanficInfo:
    """
    Generate a FanficInfo object from a URL by identifying the site and normalizing the URL.

    This function uses auto-generated URL parsers to identify the fanfiction
    site and extract the story identifier from the URL. It then normalizes
    the URL format and creates a FanficInfo object with proper site classification.

    Args:
        url: The fanfiction story URL to process. Can be in various formats
             depending on the source site (e.g., full URL, shortened URL, etc.)

    Returns:
        fanfic_info.FanficInfo: Object containing the normalized URL and site
                               identification. Site will be "other" if not recognized.

    Processing Flow:
        1. Test URL against each auto-generated site parser
        2. Extract story ID or URL components using regex capture groups
        3. Reconstruct normalized URL using site's prefix pattern
        4. Create FanficInfo object with site identification
        5. Fall back to "other" site for unrecognized URLs

    Example:
        ```python
        # Archive of Our Own URL
        info = generate_FanficInfo_from_url("https://archiveofourown.org/works/12345", url_parsers)
        # Returns: FanficInfo(url="https://archiveofourown.org/works/12345", site="archiveofourown.org")

        # FanFiction.Net URL
        info = generate_FanficInfo_from_url("https://www.fanfiction.net/s/789123/1/", url_parsers)
        # Returns: FanficInfo(url="https://www.fanfiction.net/s/789123", site="fanfiction.net")

        # Unrecognized site
        info = generate_FanficInfo_from_url("https://unknown-site.com/story/456", url_parsers)
        # Returns: FanficInfo(url="https://unknown-site.com/story/456", site="other")
        ```

    URL Normalization:
        The function normalizes URLs by extracting the essential story
        identifier and reconstructing the URL using the site's standard
        format. This ensures consistent URL handling across the application.

    Site Recognition:
        Site identification is based on auto-generated parsers from FanFicFare's
        adapter definitions. This automatically supports new sites as they are
        added to FanFicFare without requiring manual updates to this code.

    Note:
        The "other" site classification is used for URLs that don't match
        any known fanfiction site patterns. These URLs are passed through
        unchanged but may not be supported by FanFicFare.
    """
    # Test URL against all auto-generated site parsers
    for site, (parser, prefix) in url_parsers.items():
        if match := parser.search(url):
            # Handle cases where there are multiple capture groups (e.g., for alternative patterns)
            captured_group = None
            for group in match.groups():
                if group is not None:
                    captured_group = group
                    break

            if captured_group is not None:
                # Special handling for fanfiction.net: ensure chapter number exists
                if site == "fanfiction":
                    # Check if the captured group has a chapter number (/s/ID/CHAPTER)
                    if not re.search(r'/s/\d+/\d+', captured_group):
                        # No chapter number, add /1/ as default
                        captured_group = captured_group.rstrip('/') + '/1/'
                    elif not captured_group.endswith('/'):
                        # Has chapter but no trailing slash, add it for consistency
                        captured_group = captured_group + '/'

                # Reconstruct URL using site's prefix and captured story ID
                url = prefix + captured_group
            else:
                # Fallback: use the entire matched portion
                url = match.group(0)

            return fanfic_info.FanficInfo(url, site, title=url)

    # No recognized site pattern matched - classify as "other"
    return fanfic_info.FanficInfo(url, "other", title=url)
